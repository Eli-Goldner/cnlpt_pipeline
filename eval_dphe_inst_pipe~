task=dphe_rel
dir="/home/ch231037/r/DeepPhe_CR/med_system/relations/medrel"
epochs=10
lr=2e-5
ev_per_ep=2
stl=0
seed=42
gas=4
encoder=roberta-base
model_dir="/home/ch231037/Repos/cnlp_transformers/temp/"
python -m cnlpt.train_system --task_name $task \
--data_dir $dir \
--encoder_name $model_dir \
--cache /home/ch231037/Repos/cnlp_transformers/cache/ \
--output_dir /home/ch231037/Repos/cnlp_transformers/temp/ \
--overwrite_output_dir \
--do_eval \
--learning_rate $lr \
--seed $seed \
--gradient_accumulation_steps $gas \
--tokenizer_name $encoder